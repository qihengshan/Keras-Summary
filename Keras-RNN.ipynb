{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras实现Recurrent Neural Networks\n",
    "\n",
    "使用MNIST数据集，主要用SimpleRNN实现。(LSTM, GRU是LSTM的简化版本，只有2个Gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(100)  # for reproducibility\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Activation, SimpleRNN\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理\n",
    "* MNIST里面的图像分辨率是28×28，为了使用RNN，我们将图像理解为序列化数据。 每一行作为一个输入单元，所以输入数据大小INPUT_SIZE = 28； 先是第1行输入，再是第2行，第3行，第4行，…，第28行输入， 这就是一张图片也就是一个序列，所以步长TIME_STEPS = 28。\n",
    "* 训练数据要进行归一化处理，因为原始数据是8bit灰度图像所以需要除以255。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the mnist to the path '~/.keras/datasets/' if it is the first time to be called\n",
    "# X shape (60000, 28, 28), y shape (60000,)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# data pre-processing\n",
    "X_train = X_train.reshape(-1, 28, 28) / 255.   # normalize\n",
    "X_test = X_test.reshape(-1, 28, 28) / 255.      # normalize\n",
    "# convert to category \n",
    "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 28  # 等于图片高度，时间长度，28个时间点\n",
    "INPUT_SIZE = 28  # 等于图片宽度，每一行读取多少个pixel\n",
    "BATCH_SIZE = 100  # 一个批次图片数\n",
    "BATCH_INDEX = 0\n",
    "OUTPUT_SIZE = 10\n",
    "CELL_SIZE = 100   # hidden layer\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型、编译模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qihengshan/pythonEnv/python374/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(batch_input_shape=(None, 28,..., unroll=True, units=100)`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(\n",
    "    # for batch_input_shape, if using tensorflow as the backend, we have to put None for the batch_size.\n",
    "    # Otherwise, model.evaluate() will get error.\n",
    "    batch_input_shape=(None, TIME_STEPS, INPUT_SIZE),       \n",
    "    output_dim=CELL_SIZE,\n",
    "    return_sequences=False, # 只在最后一个时间点输出值\n",
    "    unroll=True,\n",
    "))\n",
    "\n",
    "model.add(Dense(OUTPUT_SIZE))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# 定义优化器\n",
    "adam = Adam(lr=0.001)\n",
    "# 编译模型\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型\n",
    "每次训练的时候并不是取所有的数据，只是取BATCH_SIZE个序列，或者称为BATCH_SIZE张图片，这样可以大大降低运算时间，提高训练效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\tTest Loss: 2.2865800857543945, \tTest accuracy: 0.13439999520778656\n",
      "Step: 1000\tTest Loss: 0.22341260313987732, \tTest accuracy: 0.933899998664856\n",
      "Step: 2000\tTest Loss: 0.17896071076393127, \tTest accuracy: 0.9490000009536743\n",
      "Step: 3000\tTest Loss: 0.16045717895030975, \tTest accuracy: 0.9528999924659729\n",
      "Step: 4000\tTest Loss: 0.15019135177135468, \tTest accuracy: 0.9578999876976013\n",
      "Step: 5000\tTest Loss: 0.11457083374261856, \tTest accuracy: 0.9667999744415283\n",
      "Step: 6000\tTest Loss: 0.13894927501678467, \tTest accuracy: 0.9609000086784363\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for step in range(601*10):  # epochs=10, 600 * 100 = 60000一个epoch\n",
    "    # data shape = (batch_num, steps, inputs/outputs)\n",
    "    X_batch = X_train[BATCH_INDEX:BATCH_INDEX+BATCH_SIZE, :, :]\n",
    "    Y_batch = y_train[BATCH_INDEX:BATCH_INDEX+BATCH_SIZE, :]\n",
    "    loss = model.train_on_batch(X_batch, Y_batch)\n",
    "    BATCH_INDEX += BATCH_SIZE\n",
    "    BATCH_INDEX = 0 if BATCH_INDEX >= X_train.shape[0] else BATCH_INDEX\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "        loss, accuracy = model.evaluate(X_test, y_test, batch_size=y_test.shape[0], verbose=False)\n",
    "        print(f\"Step: {step}\\tTest Loss: {loss}, \\tTest accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
